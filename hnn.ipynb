{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "C:\\Users\\Bloris\\Anaconda3\\envs\\bloris\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\Bloris\\Anaconda3\\envs\\bloris\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\Bloris\\Anaconda3\\envs\\bloris\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:521: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\Bloris\\Anaconda3\\envs\\bloris\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:522: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\Bloris\\Anaconda3\\envs\\bloris\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:523: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\Bloris\\Anaconda3\\envs\\bloris\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:528: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "from keras.models import load_model\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D, ZeroPadding2D, Convolution2D, BatchNormalization\n",
    "from keras.layers import Activation, Dropout, Flatten, Dense\n",
    "from keras.optimizers import SGD\n",
    "from keras import backend as K\n",
    "from keras.utils import np_utils\n",
    "import pandas\n",
    "import sys\n",
    "import os\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def file_read(data_path):\n",
    "    x,y=[],[]\n",
    "    print('Loading data... ', end='')\n",
    "    for root, subFolder, files in os.walk(data_path):\n",
    "        for item in files:\n",
    "            if item.endswith(\".txt\"):\n",
    "                fileNamePath = str(os.path.join(root,item))\n",
    "                x1,x2=[],[]\n",
    "                f = open(fileNamePath, 'r')\n",
    "                \n",
    "                tmp=list(map(int, f.readline()[:-1]))\n",
    "                y.append(tmp)\n",
    "\n",
    "                for i in range(3):\n",
    "                    tmp=list(map(int, f.readline()[:-1].split(' ')[:-1]))\n",
    "                    x1.append([tmp])\n",
    "    \n",
    "                f.readline()\n",
    "                f.readline()\n",
    "    \n",
    "                for i in range(3):\n",
    "                    tmp=list(map(int, f.readline()[:-1].split(' ')[:-1]))\n",
    "                    x2.append([tmp])\n",
    "    \n",
    "                x1 = list(np.array(x1).T)\n",
    "                x2 = list(np.array(x2).T)\n",
    "    \n",
    "                x.append([x1,x2])\n",
    "    f.close()\n",
    "    print('%d data loaded.'%len(x))\n",
    "    return x,y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data... 443 data loaded.\n"
     ]
    }
   ],
   "source": [
    "XH,YH=file_read('hnn/train')\n",
    "XH,YH=np.array(XH),np.array(YH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(443, 2, 256, 3)\n",
      "(443, 2, 256, 3)\n",
      "(443, 2, 2)\n"
     ]
    }
   ],
   "source": [
    "XH = XH.reshape(len(x),2,256,3)\n",
    "XH.shape\n",
    "\n",
    "print(x.shape)\n",
    "print(x.shape)\n",
    "print(y.shape)\n",
    "XH = XH.astype('float32')\n",
    "XH /= 255\n",
    "YH = np_utils.to_categorical(YH)\n",
    "\n",
    "idx=np.arange(443)\n",
    "np.random.shuffle(idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_5 (Conv2D)            (None, 1, 254, 64)        1216      \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (None, 1, 254, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 1, 254, 32)        2080      \n",
      "_________________________________________________________________\n",
      "dropout_8 (Dropout)          (None, 1, 254, 32)        0         \n",
      "_________________________________________________________________\n",
      "flatten_3 (Flatten)          (None, 8128)              0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 8)                 65032     \n",
      "_________________________________________________________________\n",
      "dropout_9 (Dropout)          (None, 8)                 0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 2)                 18        \n",
      "=================================================================\n",
      "Total params: 68,346\n",
      "Trainable params: 68,346\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Bloris\\Anaconda3\\envs\\bloris\\lib\\site-packages\\ipykernel_launcher.py:6: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(64, (2, 3), activation=\"elu\", input_shape=(2, 256, 3..., padding=\"valid\")`\n",
      "  \n",
      "C:\\Users\\Bloris\\Anaconda3\\envs\\bloris\\lib\\site-packages\\ipykernel_launcher.py:9: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (1, 1), activation=\"elu\", padding=\"valid\")`\n",
      "  if __name__ == '__main__':\n"
     ]
    }
   ],
   "source": [
    "from keras import optimizers\n",
    "\n",
    "Nadam = optimizers.Nadam(lr=0.0001, beta_1=0.9, beta_2=0.999, epsilon=None, schedule_decay=0.003)\n",
    "\n",
    "cnn = Sequential()\n",
    "cnn.add(Convolution2D(64, 2, 3,border_mode=\"valid\",activation=\"elu\",input_shape=(2, 256, 3)))\n",
    "cnn.add(Dropout(0.5))\n",
    "\n",
    "cnn.add(Convolution2D(32, 1, 1, border_mode=\"valid\", activation=\"elu\"))\n",
    "cnn.add(Dropout(0.5))\n",
    "cnn.add(Flatten())\n",
    "\n",
    "cnn.add(Dense(8, activation=\"elu\"))\n",
    "cnn.add(Dropout(0.5))\n",
    "\n",
    "cnn.add(Dense(2, activation=\"softmax\"))\n",
    "\n",
    "cnn.summary()\n",
    "\n",
    "cnn.compile(loss='categorical_crossentropy', optimizer=Nadam, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "443/443 [==============================] - 1s 1ms/step - loss: 2.4644 - acc: 0.4989\n",
      "Epoch 2/50\n",
      "443/443 [==============================] - 0s 691us/step - loss: 1.2864 - acc: 0.5440\n",
      "Epoch 3/50\n",
      "443/443 [==============================] - 0s 669us/step - loss: 1.0329 - acc: 0.5824\n",
      "Epoch 4/50\n",
      "443/443 [==============================] - 0s 680us/step - loss: 0.9606 - acc: 0.5688\n",
      "Epoch 5/50\n",
      "443/443 [==============================] - 0s 669us/step - loss: 0.9657 - acc: 0.5372\n",
      "Epoch 6/50\n",
      "443/443 [==============================] - 0s 682us/step - loss: 0.9272 - acc: 0.5711\n",
      "Epoch 7/50\n",
      "443/443 [==============================] - 0s 664us/step - loss: 0.7970 - acc: 0.5869\n",
      "Epoch 8/50\n",
      "443/443 [==============================] - 0s 653us/step - loss: 0.8102 - acc: 0.6208\n",
      "Epoch 9/50\n",
      "443/443 [==============================] - 0s 673us/step - loss: 0.7653 - acc: 0.6117\n",
      "Epoch 10/50\n",
      "443/443 [==============================] - 0s 667us/step - loss: 0.7729 - acc: 0.6433\n",
      "Epoch 11/50\n",
      "443/443 [==============================] - 0s 671us/step - loss: 0.7804 - acc: 0.6433\n",
      "Epoch 12/50\n",
      "443/443 [==============================] - 0s 651us/step - loss: 0.7391 - acc: 0.6727\n",
      "Epoch 13/50\n",
      "443/443 [==============================] - 0s 667us/step - loss: 0.7202 - acc: 0.6682\n",
      "Epoch 14/50\n",
      "443/443 [==============================] - 0s 689us/step - loss: 0.7088 - acc: 0.6727\n",
      "Epoch 15/50\n",
      "443/443 [==============================] - 0s 651us/step - loss: 0.7056 - acc: 0.6930\n",
      "Epoch 16/50\n",
      "443/443 [==============================] - 0s 664us/step - loss: 0.7372 - acc: 0.6704\n",
      "Epoch 17/50\n",
      "443/443 [==============================] - 0s 667us/step - loss: 0.6179 - acc: 0.6885\n",
      "Epoch 18/50\n",
      "443/443 [==============================] - 0s 678us/step - loss: 0.6917 - acc: 0.7472\n",
      "Epoch 19/50\n",
      "443/443 [==============================] - 0s 671us/step - loss: 0.6290 - acc: 0.6885\n",
      "Epoch 20/50\n",
      "443/443 [==============================] - 0s 660us/step - loss: 0.6138 - acc: 0.7133\n",
      "Epoch 21/50\n",
      "443/443 [==============================] - 0s 689us/step - loss: 0.5848 - acc: 0.7314\n",
      "Epoch 22/50\n",
      "443/443 [==============================] - 0s 644us/step - loss: 0.5997 - acc: 0.7201\n",
      "Epoch 23/50\n",
      "443/443 [==============================] - 0s 648us/step - loss: 0.5937 - acc: 0.6998\n",
      "Epoch 24/50\n",
      "443/443 [==============================] - 0s 673us/step - loss: 0.5747 - acc: 0.7449\n",
      "Epoch 25/50\n",
      "443/443 [==============================] - 0s 664us/step - loss: 0.5204 - acc: 0.7698\n",
      "Epoch 26/50\n",
      "443/443 [==============================] - 0s 685us/step - loss: 0.5794 - acc: 0.7269\n",
      "Epoch 27/50\n",
      "443/443 [==============================] - 0s 664us/step - loss: 0.5298 - acc: 0.7404\n",
      "Epoch 28/50\n",
      "443/443 [==============================] - 0s 653us/step - loss: 0.5595 - acc: 0.7562\n",
      "Epoch 29/50\n",
      "443/443 [==============================] - 0s 664us/step - loss: 0.5359 - acc: 0.7494\n",
      "Epoch 30/50\n",
      "443/443 [==============================] - 0s 678us/step - loss: 0.5756 - acc: 0.7427\n",
      "Epoch 31/50\n",
      "443/443 [==============================] - 0s 646us/step - loss: 0.5107 - acc: 0.7562\n",
      "Epoch 32/50\n",
      "443/443 [==============================] - 0s 662us/step - loss: 0.4651 - acc: 0.7788\n",
      "Epoch 33/50\n",
      "443/443 [==============================] - 0s 676us/step - loss: 0.5150 - acc: 0.7743\n",
      "Epoch 34/50\n",
      "443/443 [==============================] - 0s 671us/step - loss: 0.4441 - acc: 0.7946\n",
      "Epoch 35/50\n",
      "443/443 [==============================] - 0s 662us/step - loss: 0.4684 - acc: 0.7607\n",
      "Epoch 36/50\n",
      "443/443 [==============================] - 0s 680us/step - loss: 0.4532 - acc: 0.7788\n",
      "Epoch 37/50\n",
      "443/443 [==============================] - 0s 655us/step - loss: 0.4331 - acc: 0.7607\n",
      "Epoch 38/50\n",
      "443/443 [==============================] - 0s 712us/step - loss: 0.5032 - acc: 0.7810\n",
      "Epoch 39/50\n",
      "443/443 [==============================] - 0s 664us/step - loss: 0.4185 - acc: 0.7856\n",
      "Epoch 40/50\n",
      "443/443 [==============================] - 0s 680us/step - loss: 0.3846 - acc: 0.8194\n",
      "Epoch 41/50\n",
      "443/443 [==============================] - 0s 653us/step - loss: 0.3865 - acc: 0.8172\n",
      "Epoch 42/50\n",
      "443/443 [==============================] - 0s 705us/step - loss: 0.4290 - acc: 0.8081\n",
      "Epoch 43/50\n",
      "443/443 [==============================] - 0s 673us/step - loss: 0.4118 - acc: 0.7901\n",
      "Epoch 44/50\n",
      "443/443 [==============================] - 0s 667us/step - loss: 0.4126 - acc: 0.7968\n",
      "Epoch 45/50\n",
      "443/443 [==============================] - 0s 703us/step - loss: 0.3448 - acc: 0.8284\n",
      "Epoch 46/50\n",
      "443/443 [==============================] - 0s 676us/step - loss: 0.3438 - acc: 0.8172\n",
      "Epoch 47/50\n",
      "443/443 [==============================] - 0s 685us/step - loss: 0.3123 - acc: 0.8420\n",
      "Epoch 48/50\n",
      "443/443 [==============================] - 0s 680us/step - loss: 0.4193 - acc: 0.8352\n",
      "Epoch 49/50\n",
      "443/443 [==============================] - 0s 664us/step - loss: 0.3632 - acc: 0.8217\n",
      "Epoch 50/50\n",
      "443/443 [==============================] - 0s 680us/step - loss: 0.3449 - acc: 0.8262\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x27f5fe7fdd8>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnn.fit(XH, YH, batch_size=4, nb_epoch=50, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import *\n",
    "\n",
    "from keras.utils import *\n",
    "\n",
    "cnn.save('weights_hnn_fit_aug.h5')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
